{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrmr4MPs9p7F"
      },
      "source": [
        "# Varroa Counter\n",
        "## 1.  D√©finition du probl√®me\n",
        "\n",
        "Les colonies d'abeilles du monde entier sont infest√©es par un parasite qui s'appelle le varroa destructor.\n",
        "Ce parasite au nom barbare se fixe sur le corps des abeilles adultes et se nourrit de l'h√©molymphe. Les femelles p√©n√®trent aussi dans les cellules opercul√©es pour se reproduire sur les larves, ce qui cr√©e plusieurs g√©n√©rations au sein d'une m√™me cellule.\n",
        "Le varroa transmet des virus aux abeilles et affaiblit leur syst√®me immunitaire.\n",
        "Si rien n'est entrepris pour stopper leur prolif√©ration, les colonies finissent par s'effondrer durant l'automne ou l'hiver.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/geda/varroacounter/blob/main/varroa_destructor.jpg?raw=1\" width=\"50%\">\n",
        "\n",
        "Une fois la r√©colte du miel effectu√©e, les apiculteurs effectuent diff√©rents traitements sur les colonies, notamment en utilisant de l'acide formique et de l'acide oxalique.\n",
        "Une fois le traitement effectu√©, l'apiculteur d√©pose une planchette sous la ruche afin d'√©valuer le degr√© d'infestation des colonies. Quelques jours apr√®s le traitement, les varroas morts tombent sur le fond de la ruche.\n",
        "Les varroas ayant une taille de 1 √† 2 mm, il devient tr√®s difficile de les compter lorsqu'ils sont nombreux. De plus, des r√©sidus de cires d'abeilles tombent √©galement des cadres, ce qui complique encore plus le comptage.\n",
        "\n",
        "<img src=\"https://github.com/geda/varroacounter/blob/main/fond_varroas.jpg?raw=1\" width=\"50%\">\n",
        "\n",
        "Les varroas sont les petites formes sombres allong√©es et arrondies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehRhkqZa9p7I"
      },
      "source": [
        "## 2. Collecte de donn√©es\n",
        "En recherchant des sets de donn√©es, j'en ai trouv√© plusieurs disponibles sur https://universe.roboflow.com/, mais aucun dataset ne correspondait parfaitement √† mes besoins:\n",
        "* Images de varroas sur les abeilles et non sur la planche\n",
        "* Images d'entra√Ænement trop petites\n",
        "* Images avec des varroas labellis√©s mais qui ne ressemblent pas vraiment √† des varroas\n",
        "\n",
        "J'ai donc cr√©√© un dataset avec mes propres images et j'en ai rajout√© quelques-une trouv√© sur le net. J'ai uploader le dataset sur roboflow sous le projet suivant: https://app.roboflow.com/varroa-counter/varroa-counter-v3/browse\n",
        "\n",
        "### Inspection des donn√©es\n",
        "Le dataset de donn√©es comprend des\n",
        "* 32 images d'entra√Ænement (71%)\n",
        "* 13 images de validation (19%)\n",
        "* 7 images de test (12%)\n",
        "\n",
        "## 3. Pr√©paration des Donn√©es\n",
        "La taille maximal pour le redimmensionnent √©tant de 2048 sur Roboflow, j'ai redimensionn√© les images 1536 x 2048 pixels.\n",
        "\n",
        "J'ai labellis√© les 32 images en identifiant plus 1000 varroas. J'ai effectu√© ce travail tr√®s chronophage directement sur roboflow.\n",
        "\n",
        "\n",
        "Chaque image de ce set a donc maintenant un label associ√©. Un seul nom de classe est utilis√© pour ce dataset: **varroa**\n",
        "Les labels associ√©s √† une image sont sauvegard√©s au format YOLO et comprennent simplement une suite de nombres comme ceci:\n",
        "* 0 0.02587890625 0.25439453125 0.0107421875 0.0166015625\n",
        "* 0 0.021484375 0.27880859375 0.009765625 0.0166015625\n",
        "* 0 0.0751953125 0.3349609375 0.009765625 0.015625\n",
        "* ...\n",
        "\n",
        "#### Explication du format YOLO\n",
        "\n",
        "```\n",
        "0 0.02587890625 0.25439453125 0.0107421875 0.0166015625\n",
        "‚îÇ      ‚îÇ              ‚îÇ            ‚îÇ            ‚îÇ\n",
        "‚îÇ      ‚îÇ              ‚îÇ            ‚îÇ            ‚îî‚îÄ‚îÄ height (hauteur normalis√©e de la bounding box)\n",
        "‚îÇ      ‚îÇ              ‚îÇ            ‚îî‚îÄ‚îÄ width (largeur normalis√©e de la bounding box)\n",
        "‚îÇ      ‚îÇ              ‚îî‚îÄ‚îÄ y_center (position Y du centre, normalis√©e)\n",
        "‚îÇ      ‚îî‚îÄ‚îÄ x_center (position X du centre, normalis√©e)\n",
        "‚îî‚îÄ‚îÄ class_id (identifiant de la classe = 0 = varroa)\n",
        "```\n",
        "\n",
        "| Valeur | Signification | Exemple |\n",
        "|--------|---------------|---------|\n",
        "| `0` | ID de la classe | varroa (seule classe du dataset) |\n",
        "| `0.0259` | x_center | Le centre est √† 2.6% de la largeur de l'image (tr√®s √† gauche) |\n",
        "| `0.2544` | y_center | Le centre est √† 25.4% de la hauteur de l'image |\n",
        "| `0.0107` | width | La box fait 1.07% de la largeur de l'image |\n",
        "| `0.0166` | height | La box fait 1.66% de la hauteur de l'image |\n",
        "\n",
        "## 4. Analyse Exploratoire des Donn√©es (AED)\n",
        "Les donn√©es contiennent des images avec des fonds de diff√©rentes couleurs et mati√®res.\n",
        "\n",
        "## 5. Feature Engineering\n",
        "Le mod√®le devra faire de la d√©tection d'objets. Un des challenges sera de d√©tecter des objets tr√®s petits dans les images.\n",
        "Les 2 features importantes de la d√©tection d'objets seront:\n",
        "* Classification d'image: d√©terminer si des varroas sont pr√©sents dans l'image\n",
        "* Localisation d'objet: trouver la position des varroas √† l'aide de _bounding boxes_\n",
        "\n",
        "## 6. Mod√©lisation\n",
        "Je choisi la classification comme mod√®le d'apprentissage.\n",
        "\n",
        "Je divise mon ensemble de donn√©e comme ceci:\n",
        "* 26 images d'entra√Ænement (80%)\n",
        "* 4 images de validation (12%)\n",
        "* 2 images de test (8%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84rjtpAA9p7J",
        "outputId": "389c4835-d2ec-461e-b463-f3b02d25d4d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: roboflow in d:\\dev\\python\\python312\\lib\\site-packages (1.2.11)\n",
            "Requirement already satisfied: certifi in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2025.11.12)\n",
            "Requirement already satisfied: idna==3.7 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (3.10.8)\n",
            "Requirement already satisfied: numpy>=1.18.5 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2.2.6)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (12.0.0)\n",
            "Requirement already satisfied: pi-heif<2 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2.32.5)\n",
            "Requirement already satisfied: six in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2.6.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\david\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\dev\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\dev\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (4.61.1)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\dev\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=3 in d:\\dev\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (3.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\dev\\python\\python312\\lib\\site-packages (from requests->roboflow) (3.4.4)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=str(os.getenv(\"ROBOFLOW_API_KEY\")))\n",
        "\n",
        "project = rf.workspace(\"varroa-counter\").project(\"varroa-counter-large\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Glj4EUY89p7M"
      },
      "source": [
        "## 7. Entra√Ænement du mod√®le\n",
        "### üìå Version de Python recommand√©e\n",
        "\n",
        "Pour cet exercice de r√©seaux de neurones convolutifs (CNN) avec YOLO11n, je vais utiliser **Python 3.12.7**, car c‚Äôest l‚Äôune des versions les mieux support√©es par YOLO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhIOWxWd9p7N",
        "outputId": "1523a8bb-a1c0-4c35-cbfa-b5310ef2d616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\n",
            "d:\\dev\\python\\Python312\\python.exe\n"
          ]
        }
      ],
      "source": [
        "# V√©rifions la version de Python et du chemin de l'ex√©cutable\n",
        "import sys\n",
        "print(sys.version)\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX4V3quU9p7N"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "# import the needed librairies\n",
        "import ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQcn_tUO9p7O",
        "outputId": "5e87c986-b24d-433d-8069-b4f6a19cc08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.4.8 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=0.1, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=varroa-counter-v3-2/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=2048, int8=False, iou=0.5, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=2000, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\dev\\runs\\detect\\train22, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 31.29.2 MB/s, size: 309.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-2\\train\\labels... 26 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 26/26 203.2it/s 0.1s.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-2\\train\\labels.cache\n",
            "WARNING Box and segment counts should be equal, but got len(segments) = 209, len(boxes) = 920. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 27.06.4 MB/s, size: 282.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-2\\valid\\labels... 4 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 282.9it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-2\\valid\\labels.cache\n",
            "Plotting labels to D:\\dev\\runs\\detect\\train22\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 2048 train, 2048 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mD:\\dev\\runs\\detect\\train22\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "# entrainement du mod√®le\n",
        "# Je cr√©er un nouveau mod√®le depuis z√©ro\n",
        "model = YOLO('yolo11n.pt')\n",
        "\n",
        "# lancement de l'entra√Ænement avec seulement 1 seul passage et en abaissant le nombre de batch (nombre d'images trait√©es simultan√©ment).\n",
        "# le but est de tester si les capacit√©es de ma machine sont suffisantes pour entra√Æner mon mod√®le\n",
        "results = model.train(data=\"varroa-counter-v3-2/data.yaml\", epochs=1, imgsz=2048, batch=8,\n",
        "                      max_det=2000, conf=0.1, iou = 0.5)\n",
        "print (results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ibhYcVM9p7O"
      },
      "source": [
        "Impossible d'entra√Æner mon mod√®le sur ma machine, car elle n'a pas de GPU et le kernel crash.\n",
        "J'ai fait un essai en utilisant google colab, qui permet gratuitement d'entra√Æner des mod√®les avec un peu de GPU. Malheureusement j'ai le m√™me probl√®me sur google colab qui m'indique que ma session a plant√© apr√®s avoir utilis√© toute la RAM disponible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YBiNeqY9p7P"
      },
      "source": [
        "### Changement de strat√©gie: recherche d'un mod√®le existant\n",
        "Je d√©cide donc de rechercher un mod√®le existant pouvant couvrir mes besoins et j'ai trouv√© le travail de recherche suivant: https://www.mdpi.com/2077-0472/15/9/969\n",
        "\n",
        "**R√©f√©rence:**\n",
        "> Y√°niz, J.; Casalongue, M.; Martinez-de-Pison, F.J.; Silvestre, M.A.; Consortium, B.; Santolaria, P.; Divas√≥n, J. *An AI-Based Open-Source Software for Varroa Mite Fall Analysis in Honeybee Colonies*. Agriculture 2025, 15, 969. https://doi.org/10.3390/agriculture15090969\n",
        "\n",
        "Leurs mod√®le a √©t√© entra√Æn√© avec un dataset de 357 images sur plus de 500 epochs. Ils ont √©galement livr√© un programme √©crit en python permettant d'upload ses images et d'effectuer la d√©tection des varroas avec leurs mod√®le.\n",
        "Le code source est disponible sous github ainsi que leurs mod√®le entra√Æn√©: https://github.com/jodivaso/varrodetector/blob/main/model/weights/best.pt\n",
        "\n",
        "En analysant le code j'ai trouv√© particuli√®rement int√©ressant qu'ils utilisent une taille d'image assez grande de 6016 pixels (https://github.com/jodivaso/varrodetector/blob/main/varroa_mite_gui.py#L2507C42-L2507C46).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NidNl-Gg9p7P"
      },
      "source": [
        "## 8. Evaluation du mod√®le\n",
        "Je d√©cide de rebalancer toutes les images de mon dataset en set de test et de n'appliquer aucun redimensionnement d'image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fkp0QrC9p7P",
        "outputId": "67638d95-8b43-4726-a98d-600794954648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in varroa-counter-v3-3 to yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50577/50577 [00:02<00:00, 20475.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to varroa-counter-v3-3 in yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:00<00:00, 555.15it/s]\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"tEQkmVJiCxGOZMuDLR6d\")\n",
        "project = rf.workspace(\"varroa-counter\").project(\"varroa-counter-v3\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwJxY3fV9p7Q"
      },
      "source": [
        "Il faut maintenant tester le mod√®le cr√©er par l'√©tude espagnole avec mon dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0OL17Lf9p7Q",
        "outputId": "4bdf5042-c10f-483f-de98-9530f6de3879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING imgsz=[3000] must be multiple of max stride 32, updating to [3008]\n",
            "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1561.7254.2 MB/s, size: 282.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-2\\valid\\labels.cache... 4 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4  0.0s\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Charger le mod√®le entra√Æn√©\n",
        "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
        "\n",
        "# Effectuer la d√©tection sur l'image\n",
        "results = model.val(\n",
        "    data=\"varroa-counter-v3-2/data.yaml\",\n",
        "    split='val',  # or 'val' for validation set\n",
        "    imgsz=3000,\n",
        "    batch=8,\n",
        "    conf=0.1,  # Seuil de confiance\n",
        "    iou=0.5,\n",
        "    max_det=2000\n",
        ")\n",
        "\n",
        "# Afficher les r√©sultats\n",
        "# Print results\n",
        "print(f\"Precision: {results.box.p}\")\n",
        "print(f\"Recall: {results.box.r}\")\n",
        "print(f\"mAP50: {results.box.map50}\")\n",
        "print(f\"mAP50-95: {results.box.map}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFuXIM3O9p7R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fxVQVRA9p7W",
        "outputId": "a6f4af29-15ff-40a3-ad98-ccb2593f707b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "\u001b[34m\u001b[1mval: \u001b[0mError loading data from None\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py:165\u001b[39m, in \u001b[36mBaseDataset.get_img_files\u001b[39m\u001b[34m(self, img_path)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m img_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img_path, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [img_path]:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     p = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# os-agnostic\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m p.is_dir():  \u001b[38;5;66;03m# dir\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\pathlib.py:1162\u001b[39m, in \u001b[36mPath.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1161\u001b[39m     warnings._deprecated(\u001b[33m\"\u001b[39m\u001b[33mpathlib.PurePath(**kwargs)\u001b[39m\u001b[33m\"\u001b[39m, msg, remove=(\u001b[32m3\u001b[39m, \u001b[32m14\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\pathlib.py:373\u001b[39m, in \u001b[36mPurePath.__init__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    374\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33margument should be a str or an os.PathLike \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    375\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mobject where __fspath__ returns a str, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    376\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    377\u001b[39m paths.append(path)\n",
            "\u001b[31mTypeError\u001b[39m: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m'\u001b[39m\u001b[33mmodel_mdpi_3291496/weights/best.pt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVarroa-board-1/data.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Utiliser le split 'test'\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m6016\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_width\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_txt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_conf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mR√©sultats de validation sur Varroa-board-1:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPr√©cision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults.box.p\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:611\u001b[39m, in \u001b[36mModel.val\u001b[39m\u001b[34m(self, validator, **kwargs)\u001b[39m\n\u001b[32m    608\u001b[39m args = {**\u001b[38;5;28mself\u001b[39m.overrides, **custom, **kwargs, \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[32m    610\u001b[39m validator = (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._smart_load(\u001b[33m\"\u001b[39m\u001b[33mvalidator\u001b[39m\u001b[33m\"\u001b[39m))(args=args, _callbacks=\u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics = validator.metrics\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m validator.metrics\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\validator.py:186\u001b[39m, in \u001b[36mBaseValidator.__call__\u001b[39m\u001b[34m(self, trainer, model)\u001b[39m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.rect = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28mself\u001b[39m.stride = model.stride  \u001b[38;5;66;03m# used in get_dataloader() for padding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28mself\u001b[39m.dataloader = \u001b[38;5;28mself\u001b[39m.dataloader \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m model.eval()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.compile:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:313\u001b[39m, in \u001b[36mDetectionValidator.get_dataloader\u001b[39m\u001b[34m(self, dataset_path, batch_size)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_path: \u001b[38;5;28mstr\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m) -> torch.utils.data.DataLoader:\n\u001b[32m    304\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct and return dataloader.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m    306\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    311\u001b[39m \u001b[33;03m        (torch.utils.data.DataLoader): DataLoader for validation.\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m build_dataloader(\n\u001b[32m    315\u001b[39m         dataset,\n\u001b[32m    316\u001b[39m         batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    321\u001b[39m         pin_memory=\u001b[38;5;28mself\u001b[39m.training,\n\u001b[32m    322\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:301\u001b[39m, in \u001b[36mDetectionValidator.build_dataset\u001b[39m\u001b[34m(self, img_path, mode, batch)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m, batch: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> torch.utils.data.Dataset:\n\u001b[32m    291\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build YOLO Dataset.\u001b[39;00m\n\u001b[32m    292\u001b[39m \n\u001b[32m    293\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    299\u001b[39m \u001b[33;03m        (Dataset): YOLO dataset.\u001b[39;00m\n\u001b[32m    300\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_yolo_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\build.py:236\u001b[39m, in \u001b[36mbuild_yolo_dataset\u001b[39m\u001b[34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[39;00m\n\u001b[32m    235\u001b[39m dataset = YOLOMultiModalDataset \u001b[38;5;28;01mif\u001b[39;00m multi_modal \u001b[38;5;28;01melse\u001b[39;00m YOLODataset\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# augmentation\u001b[39;49;00m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: probably add a get_hyps_from_cfg function\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# rectangular batches\u001b[39;49;00m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolorstr\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfraction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfraction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\dataset.py:88\u001b[39m, in \u001b[36mYOLODataset.__init__\u001b[39m\u001b[34m(self, data, task, *args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.data = data\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.use_segments \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_keypoints), \u001b[33m\"\u001b[39m\u001b[33mCan not use both segments and keypoints.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchannels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py:117\u001b[39m, in \u001b[36mBaseDataset.__init__\u001b[39m\u001b[34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.channels = channels\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.cv2_flag = cv2.IMREAD_GRAYSCALE \u001b[38;5;28;01mif\u001b[39;00m channels == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cv2.IMREAD_COLOR\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28mself\u001b[39m.im_files = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_img_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mself\u001b[39m.labels = \u001b[38;5;28mself\u001b[39m.get_labels()\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.update_labels(include_class=classes)  \u001b[38;5;66;03m# single_cls and include_class\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py:181\u001b[39m, in \u001b[36mBaseDataset.get_img_files\u001b[39m\u001b[34m(self, img_path)\u001b[39m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m im_files, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mNo images found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFORMATS_HELP_MSG\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mError loading data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mHELP_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fraction < \u001b[32m1\u001b[39m:\n\u001b[32m    183\u001b[39m     im_files = im_files[: \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mlen\u001b[39m(im_files) * \u001b[38;5;28mself\u001b[39m.fraction)]  \u001b[38;5;66;03m# retain a fraction of the dataset\u001b[39;00m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: \u001b[34m\u001b[1mval: \u001b[0mError loading data from None\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance."
          ]
        }
      ],
      "source": [
        "# Test du mod√®le avec le dataset Varroa-board-1\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
        "\n",
        "results = model.val(\n",
        "    data=\"Varroa-board-1/data.yaml\",\n",
        "    split='test',  # Utiliser le split 'test'\n",
        "    imgsz=(6016), max_det=2000, conf=0.1, iou = 0.5,\n",
        "    save=True, show_labels=False, line_width=2, save_txt=True, save_conf=True\n",
        ")\n",
        "\n",
        "print(\"\\nR√©sultats de validation sur Varroa-board-1:\")\n",
        "print(f\"Pr√©cision: {results.box.p}\")\n",
        "print(f\"Recall: {results.box.r}\")\n",
        "print(f\"mAP50: {results.box.map50}\")\n",
        "print(f\"mAP50-95: {results.box.map}\")\n",
        "\n",
        "#R√©sultats de validation sur Varroa-board-1:\n",
        "#Pr√©cision: [    0.80237]\n",
        "#Recall: [    0.42177]\n",
        "#mAP50: 0.584942355545071\n",
        "#mAP50-95: 0.2293648037166341"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvLKPzdu9p7W",
        "outputId": "632d630a-d66e-481e-af43-9d5ed4c810d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille originale de l'image: 4284x5712\n",
            "Partie 1 (top_left): 2142x2856 sauvegard√©e\n",
            "Partie 2 (top_right): 2142x2856 sauvegard√©e\n",
            "Partie 3 (bottom_left): 2142x2856 sauvegard√©e\n",
            "Partie 4 (bottom_right): 2142x2856 sauvegard√©e\n",
            "\n",
            "============================================================\n",
            "D√âTECTION SUR CHAQUE PARTIE\n",
            "============================================================\n",
            "\n",
            "\n",
            "--- D√©tection sur top_left ---\n",
            "\n",
            "image 1/1 d:\\dev\\ia\\cours\\varroacounter\\temp_tiles\\tile_1_top_left.jpg: 6016x4512 108 varroas, 7910.5ms\n",
            "Speed: 315.9ms preprocess, 7910.5ms inference, 13.1ms postprocess per image at shape (1, 3, 6016, 4512)\n",
            "Results saved to \u001b[1mD:\\dev\\runs\\detect\\predict4\u001b[0m\n",
            "1 label saved to D:\\dev\\runs\\detect\\predict4\\labels\n",
            "Varroas d√©tect√©s: 108\n",
            "\n",
            "--- D√©tection sur top_right ---\n",
            "\n",
            "image 1/1 d:\\dev\\ia\\cours\\varroacounter\\temp_tiles\\tile_2_top_right.jpg: 6016x4512 109 varroas, 6570.5ms\n",
            "Speed: 272.7ms preprocess, 6570.5ms inference, 10.5ms postprocess per image at shape (1, 3, 6016, 4512)\n",
            "Results saved to \u001b[1mD:\\dev\\runs\\detect\\predict4\u001b[0m\n",
            "2 labels saved to D:\\dev\\runs\\detect\\predict4\\labels\n",
            "Varroas d√©tect√©s: 109\n",
            "\n",
            "--- D√©tection sur bottom_left ---\n",
            "\n",
            "image 1/1 d:\\dev\\ia\\cours\\varroacounter\\temp_tiles\\tile_3_bottom_left.jpg: 6016x4512 42 varroas, 7208.9ms\n",
            "Speed: 314.4ms preprocess, 7208.9ms inference, 13.6ms postprocess per image at shape (1, 3, 6016, 4512)\n",
            "Results saved to \u001b[1mD:\\dev\\runs\\detect\\predict4\u001b[0m\n",
            "3 labels saved to D:\\dev\\runs\\detect\\predict4\\labels\n",
            "Varroas d√©tect√©s: 42\n",
            "\n",
            "--- D√©tection sur bottom_right ---\n",
            "\n",
            "image 1/1 d:\\dev\\ia\\cours\\varroacounter\\temp_tiles\\tile_4_bottom_right.jpg: 6016x4512 134 varroas, 7090.5ms\n",
            "Speed: 308.0ms preprocess, 7090.5ms inference, 20.4ms postprocess per image at shape (1, 3, 6016, 4512)\n",
            "Results saved to \u001b[1mD:\\dev\\runs\\detect\\predict4\u001b[0m\n",
            "4 labels saved to D:\\dev\\runs\\detect\\predict4\\labels\n",
            "Varroas d√©tect√©s: 134\n",
            "\n",
            "============================================================\n",
            "R√âSUM√â DES D√âTECTIONS\n",
            "============================================================\n",
            "\n",
            "Nombre total de varroas d√©tect√©s: 393\n",
            "\n",
            "D√©tail par partie:\n",
            "  - top_left       : 108 varroas\n",
            "  - top_right      : 109 varroas\n",
            "  - bottom_left    :  42 varroas\n",
            "  - bottom_right   : 134 varroas\n",
            "\n",
            "Images d√©coup√©es sauvegard√©es dans: temp_tiles/\n",
            "R√©sultats de d√©tection sauvegard√©s dans: runs/detect/predict*/\n"
          ]
        }
      ],
      "source": [
        "# Test avec d√©coupage d'image en 4 parties\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Charger le mod√®le\n",
        "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
        "\n",
        "# Chemin de l'image √† tester\n",
        "image_path = 'Varroa-board-1/test/images/IMG_0226_jpg.rf.c97161f83bb98300231bd6318d7dee3b.jpg'\n",
        "\n",
        "# Charger l'image\n",
        "img = Image.open(image_path)\n",
        "width, height = img.size\n",
        "print(f\"Taille originale de l'image: {width}x{height}\")\n",
        "\n",
        "# Cr√©er un dossier pour les images d√©coup√©es\n",
        "output_dir = 'temp_tiles'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# D√©couper l'image en 4 parties (2x2)\n",
        "half_width = width // 2\n",
        "half_height = height // 2\n",
        "\n",
        "tiles = []\n",
        "positions = [\n",
        "    (0, 0, half_width, half_height, \"top_left\"),\n",
        "    (half_width, 0, width, half_height, \"top_right\"),\n",
        "    (0, half_height, half_width, height, \"bottom_left\"),\n",
        "    (half_width, half_height, width, height, \"bottom_right\")\n",
        "]\n",
        "\n",
        "# D√©couper et sauvegarder chaque partie\n",
        "for i, (x1, y1, x2, y2, name) in enumerate(positions):\n",
        "    tile = img.crop((x1, y1, x2, y2))\n",
        "    tile_path = os.path.join(output_dir, f'tile_{i+1}_{name}.jpg')\n",
        "    tile.save(tile_path)\n",
        "    tiles.append((tile_path, name, x1, y1))\n",
        "    print(f\"Partie {i+1} ({name}): {tile.size[0]}x{tile.size[1]} sauvegard√©e\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"D√âTECTION SUR CHAQUE PARTIE\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Tester le mod√®le sur chaque partie\n",
        "total_detections = 0\n",
        "all_results = []\n",
        "\n",
        "for tile_path, name, offset_x, offset_y in tiles:\n",
        "    print(f\"\\n--- D√©tection sur {name} ---\")\n",
        "    results = model.predict(\n",
        "        source=tile_path,\n",
        "   imgsz=(6016), max_det=2000, conf=0.1, iou = 0.5,\n",
        "    save=True, show_labels=False, line_width=2, save_txt=True, save_conf=True\n",
        "    )\n",
        "\n",
        "    detections = len(results[0].boxes)\n",
        "    total_detections += detections\n",
        "    all_results.append((name, detections, results[0]))\n",
        "\n",
        "    print(f\"Varroas d√©tect√©s: {detections}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"R√âSUM√â DES D√âTECTIONS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nNombre total de varroas d√©tect√©s: {total_detections}\")\n",
        "print(\"\\nD√©tail par partie:\")\n",
        "for name, count, _ in all_results:\n",
        "    print(f\"  - {name:15s}: {count:3d} varroas\")\n",
        "\n",
        "print(f\"\\nImages d√©coup√©es sauvegard√©es dans: {output_dir}/\")\n",
        "print(f\"R√©sultats de d√©tection sauvegard√©s dans: runs/detect/predict*/\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}