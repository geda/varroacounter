{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varroa Counter\n",
    "## 1.  D√©finition du probl√®me\n",
    "\n",
    "Les colonies d'abeilles du monde entier sont infest√©es par un parasite qui s'appelle le varroa destructor.\n",
    "Ce parasite au nom barbare se fixe sur le corps des abeilles adultes et se nourrit de l'h√©molymphe. Les femelles p√©n√®trent aussi dans les cellules opercul√©es pour se reproduire sur les larves, ce qui cr√©e plusieurs g√©n√©rations au sein d'une m√™me cellule.\n",
    "Le varroa transmet des virus aux abeilles et affaiblit leur syst√®me immunitaire.\n",
    "Si rien n'est entrepris pour stopper leur prolif√©ration, les colonies finissent par s'effondrer durant l'automne ou l'hiver.\n",
    "\n",
    "\n",
    "<img src=\"varroa_destructor.jpg\" width=\"50%\">\n",
    "\n",
    "Une fois la r√©colte du miel effectu√©e, les apiculteurs effectuent diff√©rents traitements sur les colonies, notamment en utilisant de l'acide formique et de l'acide oxalique.\n",
    "Une fois le traitement effectu√©, l'apiculteur d√©pose une planchette sous la ruche afin d'√©valuer le degr√© d'infestation des colonies. Quelques jours apr√®s le traitement, les varroas morts tombent sur le fond de la ruche. \n",
    "Les varroas ayant une taille de 1 √† 2 mm, il devient tr√®s difficile de les compter lorsqu'ils sont nombreux. De plus, des r√©sidus de cires d'abeilles tombent √©galement des cadres, ce qui complique encore plus le comptage.\n",
    "\n",
    "<img src=\"fond_varroas.jpg\" width=\"50%\">\n",
    "\n",
    "Les varroas sont les petites formes sombres allong√©es et arrondies.\n",
    "\n",
    "L'objectif de ce projet est d'estimer automatiquement le niveau d'infestation par les varroas √† partir d'une image. Il ne s'agit pas d'obtenir un d√©compte exact, notamment lorsque les varroas sont peu nombreux, mais plut√¥t de fournir un ordre de grandeur fiable en cas d'infestation importante ‚Äî par exemple, distinguer une image contenant 50 varroas d'une autre en contenant 200. Ce type d'√©valuation, difficile et fastidieux √† r√©aliser manuellement, est ainsi automatis√© pour faciliter le travail de l'apiculteur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collecte de donn√©es\n",
    "J'aimerais pouvoir simplement faire une photo de la planche complete et donn√© cette image assez large √† un mod√®le pour l'inf√©rence.\n",
    "J'ai donc recherch√© des sets de donn√©es sur les varroas et j'en ai trouv√© plusieurs disponibles sur https://universe.roboflow.com/. Malheureusement aucun dataset ne correspondait parfaitement √† mes besoins:\n",
    "* Images de varroas sur les abeilles et non sur la planche\n",
    "* Images d'entra√Ænement trop petites\n",
    "* Images avec des varroas labellis√©s mais qui ne ressemblent pas vraiment √† des varroas\n",
    "\n",
    "J'ai donc cr√©√© un dataset avec mes propres images et j'ai upload√© le dataset sur roboflow sous le projet suivant: https://app.roboflow.com/varroa-counter/varroa-counter-large/2\n",
    "\n",
    "### Inspection des donn√©es\n",
    "Le dataset de donn√©es comprend des\n",
    "* 32 images d'entra√Ænement (71%)\n",
    "* 13 images de validation (19%)\n",
    "* 7 images de test (12%)\n",
    "\n",
    "## 3. Pr√©paration des Donn√©es\n",
    "J'ai labellis√© les 32 images en identifiant plus 1000 varroas. J'ai effectu√© ce travail tr√®s chronophage directement sur roboflow.\n",
    "\n",
    "\n",
    "Chaque image de ce set a donc maintenant un label associ√©. Un seul nom de classe est utilis√© pour ce dataset: **varroa**\n",
    "Les labels associ√©s √† une image sont sauvegard√©s au format YOLO et comprennent simplement une suite de nombres comme ceci:\n",
    "* 0 0.02587890625 0.25439453125 0.0107421875 0.0166015625\n",
    "* 0 0.021484375 0.27880859375 0.009765625 0.0166015625\n",
    "* 0 0.0751953125 0.3349609375 0.009765625 0.015625\n",
    "* ...\n",
    "\n",
    "#### Explication du format YOLO\n",
    "\n",
    "```\n",
    "0 0.02587890625 0.25439453125 0.0107421875 0.0166015625\n",
    "‚îÇ      ‚îÇ              ‚îÇ            ‚îÇ            ‚îÇ\n",
    "‚îÇ      ‚îÇ              ‚îÇ            ‚îÇ            ‚îî‚îÄ‚îÄ height (hauteur normalis√©e de la bounding box)\n",
    "‚îÇ      ‚îÇ              ‚îÇ            ‚îî‚îÄ‚îÄ width (largeur normalis√©e de la bounding box)\n",
    "‚îÇ      ‚îÇ              ‚îî‚îÄ‚îÄ y_center (position Y du centre, normalis√©e)\n",
    "‚îÇ      ‚îî‚îÄ‚îÄ x_center (position X du centre, normalis√©e)\n",
    "‚îî‚îÄ‚îÄ class_id (identifiant de la classe = 0 = varroa)\n",
    "```\n",
    "\n",
    "| Valeur | Signification | Exemple |\n",
    "|--------|---------------|---------|\n",
    "| `0` | ID de la classe | varroa (seule classe du dataset) |\n",
    "| `0.0259` | x_center | Le centre est √† 2.6% de la largeur de l'image (tr√®s √† gauche) |\n",
    "| `0.2544` | y_center | Le centre est √† 25.4% de la hauteur de l'image |\n",
    "| `0.0107` | width | La box fait 1.07% de la largeur de l'image |\n",
    "| `0.0166` | height | La box fait 1.66% de la hauteur de l'image |\n",
    "\n",
    "## 4. Analyse Exploratoire des Donn√©es (AED)\n",
    "Les donn√©es contiennent des images avec des fonds de diff√©rentes couleurs et mati√®res.\n",
    "\n",
    "## 5. Feature Engineering\n",
    "Le mod√®le devra faire de la d√©tection d'objets. Un des challenges sera de d√©tecter des objets tr√®s petits dans les images.\n",
    "Les 2 features importantes de la d√©tection d'objets seront:\n",
    "* Classification d'image: d√©terminer si des varroas sont pr√©sents dans l'image\n",
    "* Localisation d'objet: trouver la position des varroas √† l'aide de _bounding boxes_\n",
    "\n",
    "## 6. Mod√©lisation\n",
    "Je choisi la classification comme mod√®le d'apprentissage.\n",
    "\n",
    "Je divise mon ensemble de donn√©e comme ceci:\n",
    "* 26 images d'entra√Ænement (80%)\n",
    "* 4 images de validation (12%)\n",
    "* 2 images de test (8%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in d:\\dev\\python\\python312\\lib\\site-packages (1.2.11)\n",
      "Requirement already satisfied: certifi in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2025.11.12)\n",
      "Requirement already satisfied: idna==3.7 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.4.9)\n",
      "Requirement already satisfied: matplotlib in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (3.10.8)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2.2.6)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (12.0.0)\n",
      "Requirement already satisfied: pi-heif<2 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.2.1)\n",
      "Requirement already satisfied: requests in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2.32.5)\n",
      "Requirement already satisfied: six in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (2.6.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (6.0.3)\n",
      "Requirement already satisfied: requests-toolbelt in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in d:\\dev\\python\\python312\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\dev\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\dev\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (4.61.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\dev\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in d:\\dev\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (3.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\dev\\python\\python312\\lib\\site-packages (from requests->roboflow) (3.4.4)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m rf = Roboflow(api_key=\u001b[38;5;28mstr\u001b[39m(os.getenv(\u001b[33m\"\u001b[39m\u001b[33mROBOFLOW_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m      7\u001b[39m project = rf.workspace(\u001b[33m\"\u001b[39m\u001b[33mvarroa-counter\u001b[39m\u001b[33m\"\u001b[39m).project(\u001b[33m\"\u001b[39m\u001b[33mvarroa-counter-large\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m version = \u001b[43mproject\u001b[49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m dataset = version.download(\u001b[33m\"\u001b[39m\u001b[33myolov11\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\roboflow\\core\\project.py:337\u001b[39m, in \u001b[36mProject.version\u001b[39m\u001b[34m(self, version_number, local)\u001b[39m\n\u001b[32m    323\u001b[39m         name = \u001b[33m\"\u001b[39m\u001b[33mchess-pieces-new\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Version(\n\u001b[32m    325\u001b[39m         {},\n\u001b[32m    326\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    334\u001b[39m         public=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    335\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m version_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_version_information\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m version_object \u001b[38;5;129;01min\u001b[39;00m version_info:\n\u001b[32m    340\u001b[39m     current_version_num = os.path.basename(version_object[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\roboflow\\core\\project.py:105\u001b[39m, in \u001b[36mProject.get_version_information\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_version_information\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     90\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m    Retrieve all versions of a project.\u001b[39;00m\n\u001b[32m     92\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m        >>> version_info = project.get_version_information()\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     dataset_info = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mAPI_URL\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__workspace\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__project_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m?api_key=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__api_key\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# Throw error if dataset isn't valid/user doesn't have permissions to access the dataset # noqa: E501 // docs\u001b[39;00m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dataset_info.status_code != \u001b[32m200\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:796\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    793\u001b[39m     \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[32m    794\u001b[39m     server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    814\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n\u001b[32m    816\u001b[39m \u001b[38;5;66;03m# If an error occurs during connection/handshake we may need to release\u001b[39;00m\n\u001b[32m    817\u001b[39m \u001b[38;5;66;03m# our lock so another connection can probe the origin.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:975\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    972\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[32m    973\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m975\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py:461\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ca_certs \u001b[38;5;129;01mor\u001b[39;00m ca_cert_dir \u001b[38;5;129;01mor\u001b[39;00m ca_cert_data:\n\u001b[32m    460\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m         \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_verify_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    463\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "import os\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=str(os.getenv(\"ROBOFLOW_API_KEY\")))\n",
    "\n",
    "project = rf.workspace(\"varroa-counter\").project(\"varroa-counter-large\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entra√Ænement du mod√®le\n",
    "### üìå Version de Python recommand√©e\n",
    "\n",
    "Pour cet exercice de r√©seaux de neurones convolutifs (CNN) avec YOLO11n, je vais utiliser **Python 3.12.7**, car c‚Äôest l‚Äôune des versions les mieux support√©es par YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\n",
      "d:\\dev\\python\\Python312\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# V√©rifions la version de Python et du chemin de l'ex√©cutable\n",
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "# import the needed librairies\n",
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid escape sequence '\\d'\n",
      "invalid escape sequence '\\d'\n",
      "invalid escape sequence '\\d'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.4.11 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=0.1, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=varroa-counter-large-3\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=5000, int8=False, iou=0.5, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=2000, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train27, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\dev\\runs\\detect\\train27, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "WARNING imgsz=[5000] must be multiple of max stride 32, updating to [5024]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 50.231.2 MB/s, size: 1586.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-large-3\\train\\labels... 19 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 99.5it/s 0.2s0.4s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-large-3\\train\\labels.cache\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 418, len(boxes) = 1595. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 91.57.2 MB/s, size: 1907.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-large-3\\valid\\labels... 4 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 131.2it/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-large-3\\valid\\labels.cache\n",
      "Plotting labels to D:\\dev\\runs\\detect\\train27\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 5024 train, 5024 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mD:\\dev\\runs\\detect\\train27\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# entrainement du mod√®le \n",
    "# Je cr√©er un nouveau mod√®le depuis z√©ro\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# lancement de l'entra√Ænement avec seulement 1 seul passage et en abaissant le nombre de batch (nombre d'images trait√©es simultan√©ment).\n",
    "# le but est de tester si les capacit√©es de ma machine sont suffisantes pour entra√Æner mon mod√®le\n",
    "results = model.train(data=\"varroa-counter-large-3\\data.yaml\", epochs=1, imgsz=5000, batch=2,\n",
    "                      max_det=2000, conf=0.1, iou = 0.5)\n",
    "print (results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impossible d'entra√Æner mon mod√®le sur ma machine, car elle n'a pas de GPU et le kernel crash. \n",
    "J'ai fait un essai en utilisant google colab, qui permet gratuitement d'entra√Æner des mod√®les avec un peu de GPU. Malheureusement j'ai le m√™me probl√®me sur google colab qui m'indique que ma session a plant√© apr√®s avoir utilis√© toute la RAM disponible.\n",
    "\n",
    "Le probl√®me est l'entra√Ænement de mod√®le avec des images de grandes tailles car cela n√©cessite beaucoup de m√©moire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changement de strat√©gie: recherche d'un mod√®le existant\n",
    "Je d√©cide donc de rechercher un mod√®le existant pouvant couvrir mes besoins et j'ai trouv√© le travail de recherche suivant: https://www.mdpi.com/2077-0472/15/9/969\n",
    "\n",
    "**R√©f√©rence:**\n",
    "> Y√°niz, J.; Casalongue, M.; Martinez-de-Pison, F.J.; Silvestre, M.A.; Consortium, B.; Santolaria, P.; Divas√≥n, J. *An AI-Based Open-Source Software for Varroa Mite Fall Analysis in Honeybee Colonies*. Agriculture 2025, 15, 969. https://doi.org/10.3390/agriculture15090969\n",
    "\n",
    "Leurs mod√®le a √©t√© entra√Æn√© avec un dataset de 357 images sur plus de 500 epochs. Ils ont √©galement livr√© un programme √©crit en python permettant d'upload ses images et d'effectuer la d√©tection des varroas avec leurs mod√®le.\n",
    "Le code source est disponible sous github ainsi que leurs mod√®le entra√Æn√©: https://github.com/jodivaso/varrodetector/blob/main/model/weights/best.pt\n",
    "\n",
    "En analysant le code j'ai trouv√© particuli√®rement int√©ressant qu'ils utilisent une taille d'image assez grande de 6016 pixels (https://github.com/jodivaso/varrodetector/blob/main/varroa_mite_gui.py#L2507C42-L2507C46).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation du mod√®le\n",
    "Je d√©cide de rebalancer toutes les images de mon dataset en set de test et de n'appliquer aucun redimensionnement d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"tEQkmVJiCxGOZMuDLR6d\")\n",
    "project = rf.workspace(\"varroa-counter\").project(\"varroa-counter-v3\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et de lancer le test du mod√®le avec mon dataset de test comprenant 32 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 632.795.6 MB/s, size: 1693.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-large-3\\train\\labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19  0.0s\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 418, len(boxes) = 1595. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 29.9s/it 2:2940.4s2\n",
      "                   all         19       1595      0.414      0.401      0.352     0.0985\n",
      "Speed: 124.8ms preprocess, 6928.0ms inference, 0.0ms loss, 14.1ms postprocess per image\n",
      "Saving D:\\dev\\runs\\detect\\val70\\predictions.json...\n",
      "Results saved to \u001b[1mD:\\dev\\runs\\detect\\val70\u001b[0m\n",
      "Precision: [    0.41353]\n",
      "Recall: [    0.40125]\n",
      "mAP50: 0.3521537608756259\n",
      "mAP50-95: 0.09846878398398631\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger le mod√®le entra√Æn√©\n",
    "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
    "\n",
    "# Effectuer la d√©tection sur l'image\n",
    "results = model.val(\n",
    "    data=\"varroa-counter-large-3/data.yaml\",\n",
    "    split='train',  # or 'val' for validation set\n",
    "    imgsz=6016, # m√™me valeur celle utilis√©e dans le code https://github.com/jodivaso/varrodetector/blob/main/varroa_mite_gui.py#L2507\n",
    "    batch=4,    \n",
    "    conf=0.1,  # Seuil de confiance\n",
    "    iou=0.5,\n",
    "    max_det=2000,\n",
    "    save_json=True,\n",
    "    save=True,\n",
    "    show_labels=False,\n",
    "    show_conf=False,\n",
    "    line_width=2\n",
    ")\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "# Print results\n",
    "print(f\"Precision: {results.box.p}\")\n",
    "print(f\"Recall: {results.box.r}\")\n",
    "print(f\"mAP50: {results.box.map50}\")\n",
    "print(f\"mAP50-95: {results.box.map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*En r√©sum√© la qualit√© de ce mod√®le par rapport √† mon probl√®me est faible*\n",
    "\n",
    "**Precision : 0.4135 (41%)**\n",
    "Sur toutes les d√©tections faites par le mod√®le, seulement 41% sont correctes. Cela signifie que ~59% des d√©tections sont des faux positifs (le mod√®le d√©tecte un varroa l√† o√π il n'y en a pas).\n",
    "\n",
    "**Recall : 0.4013 (40%)**\n",
    "Sur tous les varroas r√©ellement pr√©sents dans les images, le mod√®le n'en d√©tecte que 40%. Il rate donc ~60% des varroas r√©els.\n",
    "\n",
    "**mAP50 : 0.352**\n",
    "La pr√©cision moyenne (mean Average Precision) avec un seuil IoU de 50%. C'est la m√©trique standard de performance en d√©tection d'objets. Un score de 0.35 est faible.\n",
    "\n",
    "**mAP50-95 : 0.098**\n",
    "La m√™me m√©trique mais moyenn√©e sur des seuils IoU de 50% √† 95% (plus strict sur la pr√©cision de localisation). Un score de ~0.10 est tr√®s faible, ce qui indique que m√™me quand le mod√®le trouve un varroa, la bo√Æte englobante est souvent mal positionn√©e.\n",
    "\n",
    "Je d√©cide donc de faire un test avec 1 seule image afin de d√©terminer plus pr√©cis√©ment o√π le probl√®me se trouve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\dev\\ia\\cours\\varroacounter\\varroa-counter-large-3\\train\\images\\IMG_0223_cropped_jpg.rf.0e4c7399e5f9e2e6287c52cd865bae46.jpg: 6016x4544 250 varroas, 4753.5ms\n",
      "Speed: 343.0ms preprocess, 4753.5ms inference, 27.0ms postprocess per image at shape (1, 3, 6016, 4544)\n",
      "Results saved to \u001b[1mD:\\dev\\runs\\detect\\predict16\u001b[0m\n",
      "Varroas d√©tect√©s: 250\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger le mod√®le entra√Æn√©\n",
    "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
    "\n",
    "# Effectuer la d√©tection sur l'image\n",
    "results = model.predict(\n",
    "    source=\"varroa-counter-large-3/train/images/IMG_0223_cropped_jpg.rf.0e4c7399e5f9e2e6287c52cd865bae46.jpg\",\n",
    "    imgsz=6016,\n",
    "    max_det=2000,\n",
    "    conf=0.1,\n",
    "    iou=0.5,\n",
    "    save=True,\n",
    "    show_labels=False,\n",
    "    show_conf=False,\n",
    "    line_width=2\n",
    ")\n",
    "\n",
    "print(f\"Varroas d√©tect√©s: {len(results[0].boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un zoom sur l'image g√©n√©r√©e par la d√©tection\n",
    "![image annot√© apr√®s pr√©diction](IMG_0223_cropped_predict_16_zoom.jpg)\n",
    "\n",
    "On constate les probl√®mes suivants:\n",
    "- le mod√®le confond les gouttes d'eau et les varroas\n",
    "- le mod√®le oublie des varroas pourtant bien visibles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_7752\\60879843.py:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  results = model.train(data=\"varroa-counter-large-3\\data.yaml\", epochs=150, imgsz=6016, batch=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.4.11 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=0.1, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=varroa-counter-large-3\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=6016, int8=False, iou=0.5, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=2000, mixup=0.0, mode=train, model=model_mdpi_3291496/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train32, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\dev\\runs\\detect\\train32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 867.9256.8 MB/s, size: 1583.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-large-3\\train\\labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19  0.0s\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 418, len(boxes) = 1595. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1509.3535.2 MB/s, size: 1907.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-large-3\\valid\\labels.cache... 4 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.0Kit/s 0.0s\n",
      "Plotting labels to D:\\dev\\runs\\detect\\train32\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 6016 train, 6016 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mD:\\dev\\runs\\detect\\train32\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/150         0G      2.322      10.99      2.507          3       6016: 32% ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 6/19 2.8s/it 3:02<37.0s"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# entrainement du mod√®le \n",
    "# Je cr√©er un nouveau mod√®le depuis z√©ro\n",
    "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
    "\n",
    "# lancement de l'entra√Ænement avec seulement 1 seul passage et en abaissant le nombre de batch (nombre d'images trait√©es simultan√©ment).\n",
    "# le but est de tester si les capacit√©es de ma machine sont suffisantes pour entra√Æner mon mod√®le\n",
    "results = model.train(data=\"varroa-counter-large-3\\data.yaml\", epochs=150, imgsz=6016, batch=1,\n",
    "                      freeze=10, max_det=2000, conf=0.1, iou = 0.5)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je d√©cide de faire une pr√©diction valider le mod√®le avec uniquement les images provenant du site espagnol. Je ne sais pas si elles ont √©t√© utilis√©es lors de l'entra√Ænement du mod√®le, mais d√©cide de faire une comparaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset filtr√© cr√©√© dans: varroa-counter-v3-3-IMG6\n",
      "Images copi√©es: 5\n",
      "  test: 5 images\n",
      "  valid: 0 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_filtered_dataset(source_dir, dest_dir, prefix=\"IMG_6\"):\n",
    "    \"\"\"\n",
    "    Cr√©e une copie d'un dataset YOLO en ne gardant que les images\n",
    "    dont le nom commence par le pr√©fixe sp√©cifi√©.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Chemin du dataset source (ex: \"varroa-counter-v3-3\")\n",
    "        dest_dir: Chemin du dataset destination\n",
    "        prefix: Pr√©fixe des images √† conserver (ex: \"IMG_6\")\n",
    "    \"\"\"\n",
    "    source_dir = Path(source_dir)\n",
    "    dest_dir = Path(dest_dir)\n",
    "\n",
    "    # Copier data.yaml et fichiers README\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for f in source_dir.glob(\"*.yaml\"):\n",
    "        shutil.copy2(f, dest_dir / f.name)\n",
    "    for f in source_dir.glob(\"*.txt\"):\n",
    "        shutil.copy2(f, dest_dir / f.name)\n",
    "\n",
    "    total_copied = 0\n",
    "\n",
    "    # Parcourir les splits (train, valid, test)\n",
    "    for split_dir in source_dir.iterdir():\n",
    "        if not split_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        images_dir = split_dir / \"images\"\n",
    "        labels_dir = split_dir / \"labels\"\n",
    "\n",
    "        if not images_dir.exists():\n",
    "            continue\n",
    "\n",
    "        # Cr√©er les dossiers de destination\n",
    "        dest_images = dest_dir / split_dir.name / \"images\"\n",
    "        dest_labels = dest_dir / split_dir.name / \"labels\"\n",
    "        dest_images.mkdir(parents=True, exist_ok=True)\n",
    "        dest_labels.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Copier les images correspondant au pr√©fixe et leurs labels\n",
    "        for img_file in images_dir.iterdir():\n",
    "            if img_file.name.startswith(prefix):\n",
    "                shutil.copy2(img_file, dest_images / img_file.name)\n",
    "\n",
    "                # Copier le label correspondant (.txt)\n",
    "                label_file = labels_dir / (img_file.stem + \".txt\")\n",
    "                if label_file.exists():\n",
    "                    shutil.copy2(label_file, dest_labels / label_file.name)\n",
    "\n",
    "                total_copied += 1\n",
    "\n",
    "    print(f\"Dataset filtr√© cr√©√© dans: {dest_dir}\")\n",
    "    print(f\"Images copi√©es: {total_copied}\")\n",
    "\n",
    "    # Lister le contenu\n",
    "    for split_dir in sorted(dest_dir.iterdir()):\n",
    "        if split_dir.is_dir():\n",
    "            imgs = list((split_dir / \"images\").glob(\"*\"))\n",
    "            print(f\"  {split_dir.name}: {len(imgs)} images\")\n",
    "\n",
    "\n",
    "# Cr√©er le dataset filtr√© avec uniquement les images IMG_6xxx\n",
    "create_filtered_dataset(\n",
    "    source_dir=\"varroa-counter-v3-3\",\n",
    "    dest_dir=\"varroa-counter-v3-3-IMG6\",\n",
    "    prefix=\"IMG_6\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 85.96.4 MB/s, size: 1745.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-3-IMG6\\test\\labels... 5 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 118.5it/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-3-IMG6\\test\\labels.cache\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 209, len(boxes) = 745. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 123.3s/it 2:03\n",
      "                   all          5        745      0.609      0.483      0.483      0.148\n",
      "Speed: 890.8ms preprocess, 22679.2ms inference, 0.3ms loss, 49.0ms postprocess per image\n",
      "Saving D:\\dev\\runs\\detect\\val65\\predictions.json...\n",
      "Results saved to \u001b[1mD:\\dev\\runs\\detect\\val65\u001b[0m\n",
      "Precision: [    0.60893]\n",
      "Recall: [     0.4828]\n",
      "mAP50: 0.48298499787085747\n",
      "mAP50-95: 0.1482758188990101\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger le mod√®le entra√Æn√©\n",
    "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
    "\n",
    "# Effectuer la d√©tection sur l'image\n",
    "results = model.val(\n",
    "    data=\"varroa-counter-v3-3-IMG6/data.yaml\",\n",
    "    split='test',  # or 'val' for validation set\n",
    "    imgsz=6016, # m√™me valeur celle utilis√©e dans le code https://github.com/jodivaso/varrodetector/blob/main/varroa_mite_gui.py#L2507\n",
    "    batch=16,    \n",
    "    conf=0.1,  # Seuil de confiance\n",
    "    iou=0.5,\n",
    "    max_det=2000,\n",
    "    save_json=True,\n",
    "    save=True,\n",
    "    show_labels=False,\n",
    "    show_conf=False,\n",
    "    line_width=2\n",
    ")\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "# Print results\n",
    "print(f\"Precision: {results.box.p}\")\n",
    "print(f\"Recall: {results.box.r}\")\n",
    "print(f\"mAP50: {results.box.map50}\")\n",
    "print(f\"mAP50-95: {results.box.map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces r√©sultats montrent une performance am√©lior√©e par rapport √† la validation du set complet, mais quand-m√™me une performance relativement faible.\n",
    "\n",
    "Precision (0.61) ‚Äî Sur toutes les d√©tections faites, 61% sont correctes. Environ 4 d√©tections sur 10 sont des faux positifs.\n",
    "\n",
    "Recall (0.48) ‚Äî Le mod√®le ne d√©tecte que 48% des varroas r√©ellement pr√©sents. Il en rate plus de la moiti√©.\n",
    "\n",
    "mAP50 (0.48) ‚Äî Performance globale √† IoU 50% insuffisante. Un mod√®le correct vise >0.5, un bon mod√®le >0.7.\n",
    "\n",
    "mAP50-95 (0.15) ‚Äî La localisation pr√©cise est tr√®s faible. M√™me quand le mod√®le trouve un varroa, la bounding box est souvent mal positionn√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\dev\\ia\\cours\\varroacounter\\varroas\\Sample images\\IMG_6187.jpg: 6016x4512 85 varroas, 7622.3ms\n",
      "Speed: 525.4ms preprocess, 7622.3ms inference, 28.9ms postprocess per image at shape (1, 3, 6016, 4512)\n",
      "Results saved to \u001b[1mD:\\dev\\runs\\detect\\predict15\u001b[0m\n",
      "Varroas d√©tect√©s: 85\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger le mod√®le entra√Æn√©\n",
    "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
    "\n",
    "# Effectuer la d√©tection sur l'image\n",
    "results = model.predict(\n",
    "    source=\"varroas/Sample images/IMG_6187.jpg\",\n",
    "    imgsz=6016,\n",
    "    max_det=2000,\n",
    "    conf=0.1,\n",
    "    iou=0.5,\n",
    "    save=True,\n",
    "    show_labels=False,\n",
    "    show_conf=False,\n",
    "    line_width=2\n",
    ")\n",
    "\n",
    "print(f\"Varroas d√©tect√©s: {len(results[0].boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate sur l'image r√©sultant de la pr√©diction les probl√®mes suivants:\n",
    "- lorsque le varroa est pos√© sur de la cire, il est mal d√©tect√©\n",
    "- lorsque 2 varroas sont c√¥te √† c√¥te, parfois un seul varroa est d√©tect√©\n",
    "\n",
    "![image de l'√©tude annot√©](IMG_6187_predict_15_zoom.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sahi in d:\\dev\\python\\python312\\lib\\site-packages (0.11.36)\n",
      "Requirement already satisfied: click in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (8.3.1)\n",
      "Requirement already satisfied: fire in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (0.7.1)\n",
      "Requirement already satisfied: opencv-python<=4.11.0.86 in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=8.2.0 in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (12.0.0)\n",
      "Requirement already satisfied: pybboxes==0.1.6 in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (0.1.6)\n",
      "Requirement already satisfied: pyyaml in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (6.0.3)\n",
      "Requirement already satisfied: requests in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (2.32.5)\n",
      "Requirement already satisfied: shapely>=2.0.0 in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (2.1.2)\n",
      "Requirement already satisfied: terminaltables in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (3.1.10)\n",
      "Requirement already satisfied: torch>=2.4.1 in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (2.9.1)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in d:\\dev\\python\\python312\\lib\\site-packages (from sahi) (4.67.1)\n",
      "Requirement already satisfied: numpy in d:\\dev\\python\\python312\\lib\\site-packages (from pybboxes==0.1.6->sahi) (2.2.6)\n",
      "Requirement already satisfied: filelock in d:\\dev\\python\\python312\\lib\\site-packages (from torch>=2.4.1->sahi) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\dev\\python\\python312\\lib\\site-packages (from torch>=2.4.1->sahi) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\dev\\python\\python312\\lib\\site-packages (from torch>=2.4.1->sahi) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\dev\\python\\python312\\lib\\site-packages (from torch>=2.4.1->sahi) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in d:\\dev\\python\\python312\\lib\\site-packages (from torch>=2.4.1->sahi) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in d:\\dev\\python\\python312\\lib\\site-packages (from torch>=2.4.1->sahi) (2025.12.0)\n",
      "Requirement already satisfied: setuptools in d:\\dev\\python\\python312\\lib\\site-packages (from torch>=2.4.1->sahi) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\dev\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=2.4.1->sahi) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.48.2->sahi) (0.4.6)\n",
      "Requirement already satisfied: termcolor in d:\\dev\\python\\python312\\lib\\site-packages (from fire->sahi) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\dev\\python\\python312\\lib\\site-packages (from jinja2->torch>=2.4.1->sahi) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\dev\\python\\python312\\lib\\site-packages (from requests->sahi) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\dev\\python\\python312\\lib\\site-packages (from requests->sahi) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\dev\\python\\python312\\lib\\site-packages (from requests->sahi) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\dev\\python\\python312\\lib\\site-packages (from requests->sahi) (2025.11.12)\n",
      "Performing prediction on 35 slices.\n"
     ]
    }
   ],
   "source": [
    "!pip install sahi\n",
    "\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "\n",
    "model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",  # Compatible YOLO11\n",
    "    model_path=\"model_mdpi_3291496/weights/best.pt\",\n",
    "    confidence_threshold=0.1\n",
    ")\n",
    "\n",
    "result = get_sliced_prediction(\n",
    "    image=\"varroa-counter-v3-3/test/images/IMG_0223_jpg.rf.a0db71f36b6b62fd38a1deca87b0a1f0.jpg\",\n",
    "    detection_model=model,\n",
    "    slice_height=1024,\n",
    "    slice_width=1024,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2\n",
    ")\n",
    "\n",
    "result.export_visuals(export_dir=\"results/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
    "results = model.train(\n",
    "    data=\"varroa-counter-v3-2/data.yaml\",\n",
    "    epochs=150,\n",
    "    imgsz=2048,\n",
    "    batch=4,\n",
    "    freeze=10  # G√®le les premi√®res couches, ajuste seulement les derni√®res\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 138.130.7 MB/s, size: 1597.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-3\\test\\labels... 32 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 32/32 228.3it/s 0.1s.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\dev\\ia\\cours\\varroacounter\\varroa-counter-v3-3\\test\\labels.cache\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 209, len(boxes) = 1057. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 14.3s/it 28.6s49.4s\n",
      "                   all         32       1057      0.566      0.459       0.51      0.268\n",
      "Speed: 18.7ms preprocess, 592.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\dev\\runs\\detect\\val34\u001b[0m\n",
      "Precision: [    0.56554]\n",
      "Recall: [    0.45885]\n",
      "mAP50: 0.5097353357108658\n",
      "mAP50-95: 0.2684233878827464\n"
     ]
    }
   ],
   "source": [
    "# 2. Tester le mod√®le fine-tun√©\n",
    "# Le meilleur mod√®le est automatiquement sauvegard√© dans runs/detect/trainX/weights/best.pt\n",
    "model_finetuned = YOLO('runs/train23/weights/best.pt')\n",
    "\n",
    "# Validation sur le set de test\n",
    "results = model_finetuned.val(\n",
    "    data=\"varroa-counter-v3-3/data.yaml\",\n",
    "    split='test',  # ou 'val'\n",
    "    imgsz=2048,\n",
    "    conf=0.1,\n",
    "    iou=0.5,\n",
    "    max_det=2000,\n",
    "    save=True\n",
    ")\n",
    "\n",
    "print(f\"Precision: {results.box.p}\")\n",
    "print(f\"Recall: {results.box.r}\")\n",
    "print(f\"mAP50: {results.box.map50}\")\n",
    "print(f\"mAP50-95: {results.box.map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.249  Python-3.12.7 torch-2.9.1+cpu CPU (Intel Core(TM) i7-10510U 1.80GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "\u001b[34m\u001b[1mval: \u001b[0mError loading data from None\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py:165\u001b[39m, in \u001b[36mBaseDataset.get_img_files\u001b[39m\u001b[34m(self, img_path)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m img_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img_path, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [img_path]:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     p = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# os-agnostic\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m p.is_dir():  \u001b[38;5;66;03m# dir\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\pathlib.py:1162\u001b[39m, in \u001b[36mPath.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1161\u001b[39m     warnings._deprecated(\u001b[33m\"\u001b[39m\u001b[33mpathlib.PurePath(**kwargs)\u001b[39m\u001b[33m\"\u001b[39m, msg, remove=(\u001b[32m3\u001b[39m, \u001b[32m14\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\pathlib.py:373\u001b[39m, in \u001b[36mPurePath.__init__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    374\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33margument should be a str or an os.PathLike \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    375\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mobject where __fspath__ returns a str, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    376\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    377\u001b[39m paths.append(path)\n",
      "\u001b[31mTypeError\u001b[39m: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m'\u001b[39m\u001b[33mmodel_mdpi_3291496/weights/best.pt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVarroa-board-1/data.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Utiliser le split 'test'\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m6016\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_width\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_txt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_conf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mR√©sultats de validation sur Varroa-board-1:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPr√©cision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults.box.p\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:611\u001b[39m, in \u001b[36mModel.val\u001b[39m\u001b[34m(self, validator, **kwargs)\u001b[39m\n\u001b[32m    608\u001b[39m args = {**\u001b[38;5;28mself\u001b[39m.overrides, **custom, **kwargs, \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[32m    610\u001b[39m validator = (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._smart_load(\u001b[33m\"\u001b[39m\u001b[33mvalidator\u001b[39m\u001b[33m\"\u001b[39m))(args=args, _callbacks=\u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics = validator.metrics\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m validator.metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\validator.py:186\u001b[39m, in \u001b[36mBaseValidator.__call__\u001b[39m\u001b[34m(self, trainer, model)\u001b[39m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.rect = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28mself\u001b[39m.stride = model.stride  \u001b[38;5;66;03m# used in get_dataloader() for padding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28mself\u001b[39m.dataloader = \u001b[38;5;28mself\u001b[39m.dataloader \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m model.eval()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.compile:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:313\u001b[39m, in \u001b[36mDetectionValidator.get_dataloader\u001b[39m\u001b[34m(self, dataset_path, batch_size)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_path: \u001b[38;5;28mstr\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m) -> torch.utils.data.DataLoader:\n\u001b[32m    304\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct and return dataloader.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m    306\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    311\u001b[39m \u001b[33;03m        (torch.utils.data.DataLoader): DataLoader for validation.\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m build_dataloader(\n\u001b[32m    315\u001b[39m         dataset,\n\u001b[32m    316\u001b[39m         batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    321\u001b[39m         pin_memory=\u001b[38;5;28mself\u001b[39m.training,\n\u001b[32m    322\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:301\u001b[39m, in \u001b[36mDetectionValidator.build_dataset\u001b[39m\u001b[34m(self, img_path, mode, batch)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m, batch: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> torch.utils.data.Dataset:\n\u001b[32m    291\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build YOLO Dataset.\u001b[39;00m\n\u001b[32m    292\u001b[39m \n\u001b[32m    293\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    299\u001b[39m \u001b[33;03m        (Dataset): YOLO dataset.\u001b[39;00m\n\u001b[32m    300\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_yolo_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\build.py:236\u001b[39m, in \u001b[36mbuild_yolo_dataset\u001b[39m\u001b[34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[39;00m\n\u001b[32m    235\u001b[39m dataset = YOLOMultiModalDataset \u001b[38;5;28;01mif\u001b[39;00m multi_modal \u001b[38;5;28;01melse\u001b[39;00m YOLODataset\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# augmentation\u001b[39;49;00m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: probably add a get_hyps_from_cfg function\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# rectangular batches\u001b[39;49;00m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolorstr\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfraction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfraction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\dataset.py:88\u001b[39m, in \u001b[36mYOLODataset.__init__\u001b[39m\u001b[34m(self, data, task, *args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.data = data\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.use_segments \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_keypoints), \u001b[33m\"\u001b[39m\u001b[33mCan not use both segments and keypoints.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchannels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py:117\u001b[39m, in \u001b[36mBaseDataset.__init__\u001b[39m\u001b[34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.channels = channels\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.cv2_flag = cv2.IMREAD_GRAYSCALE \u001b[38;5;28;01mif\u001b[39;00m channels == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cv2.IMREAD_COLOR\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28mself\u001b[39m.im_files = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_img_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mself\u001b[39m.labels = \u001b[38;5;28mself\u001b[39m.get_labels()\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.update_labels(include_class=classes)  \u001b[38;5;66;03m# single_cls and include_class\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py:181\u001b[39m, in \u001b[36mBaseDataset.get_img_files\u001b[39m\u001b[34m(self, img_path)\u001b[39m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m im_files, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mNo images found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFORMATS_HELP_MSG\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mError loading data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mHELP_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fraction < \u001b[32m1\u001b[39m:\n\u001b[32m    183\u001b[39m     im_files = im_files[: \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mlen\u001b[39m(im_files) * \u001b[38;5;28mself\u001b[39m.fraction)]  \u001b[38;5;66;03m# retain a fraction of the dataset\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: \u001b[34m\u001b[1mval: \u001b[0mError loading data from None\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance."
     ]
    }
   ],
   "source": [
    "# Test du mod√®le avec le dataset Varroa-board-1\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
    "\n",
    "results = model.val(\n",
    "    data=\"Varroa-board-1/data.yaml\",\n",
    "    split='test',  # Utiliser le split 'test'\n",
    "    imgsz=(6016), max_det=2000, conf=0.1, iou = 0.5,\n",
    "    save=True, show_labels=False, line_width=2, save_txt=True, save_conf=True\n",
    ")\n",
    "\n",
    "print(\"\\nR√©sultats de validation sur Varroa-board-1:\")\n",
    "print(f\"Pr√©cision: {results.box.p}\")\n",
    "print(f\"Recall: {results.box.r}\")\n",
    "print(f\"mAP50: {results.box.map50}\")\n",
    "print(f\"mAP50-95: {results.box.map}\")\n",
    "\n",
    "#R√©sultats de validation sur Varroa-board-1:\n",
    "#Pr√©cision: [    0.80237]\n",
    "#Recall: [    0.42177]\n",
    "#mAP50: 0.584942355545071\n",
    "#mAP50-95: 0.2293648037166341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de SAHI pour la d√©tection par d√©coupage\n",
    "!pip install sahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 6 slices.\n",
      "Image export√©e dans: results/detection_result.png\n",
      "\n",
      "======================================================================\n",
      "R√âSUM√â DE LA D√âTECTION\n",
      "======================================================================\n",
      "\n",
      "Nombre total de varroas d√©tect√©s: 245\n",
      "\n",
      "Statistiques de confiance:\n",
      "  - Confiance moyenne: 0.629\n",
      "  - Confiance min: 0.101\n",
      "  - Confiance max: 0.939\n",
      "\n",
      "Distribution par niveau de confiance:\n",
      "  - 0.1 - 0.3: 61 d√©tections\n",
      "  - 0.3 - 0.5: 26 d√©tections\n",
      "  - 0.5 - 0.7: 15 d√©tections\n",
      "  - 0.7 - 0.9: 98 d√©tections\n",
      "  - 0.9 - 1.0: 45 d√©tections\n",
      "\n",
      "Statistiques des bounding boxes (en pixels):\n",
      "  - Aire moyenne: 3428.8 px¬≤\n",
      "  - Aire min: 294.6 px¬≤\n",
      "  - Aire max: 8172.9 px¬≤\n",
      "\n",
      "======================================================================\n",
      "D√âTAILS DES 10 PREMI√àRES D√âTECTIONS\n",
      "======================================================================\n",
      "\n",
      "D√©tection #1:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.939\n",
      "  - Bounding box: x1=2194, y1=3837, x2=2257, y2=3906\n",
      "  - Dimensions: 63x69 pixels\n",
      "  - Centre: (2226, 3871)\n",
      "\n",
      "D√©tection #2:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.932\n",
      "  - Bounding box: x1=1761, y1=1243, x2=1821, y2=1311\n",
      "  - Dimensions: 60x68 pixels\n",
      "  - Centre: (1791, 1277)\n",
      "\n",
      "D√©tection #3:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.925\n",
      "  - Bounding box: x1=2095, y1=870, x2=2162, y2=930\n",
      "  - Dimensions: 67x60 pixels\n",
      "  - Centre: (2128, 900)\n",
      "\n",
      "D√©tection #4:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.925\n",
      "  - Bounding box: x1=2816, y1=2330, x2=2877, y2=2397\n",
      "  - Dimensions: 61x67 pixels\n",
      "  - Centre: (2847, 2363)\n",
      "\n",
      "D√©tection #5:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.924\n",
      "  - Bounding box: x1=2766, y1=4686, x2=2832, y2=4747\n",
      "  - Dimensions: 66x60 pixels\n",
      "  - Centre: (2799, 4716)\n",
      "\n",
      "D√©tection #6:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.922\n",
      "  - Bounding box: x1=4479, y1=3067, x2=4543, y2=3129\n",
      "  - Dimensions: 64x62 pixels\n",
      "  - Centre: (4511, 3098)\n",
      "\n",
      "D√©tection #7:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.921\n",
      "  - Bounding box: x1=1773, y1=2939, x2=1830, y2=3002\n",
      "  - Dimensions: 58x63 pixels\n",
      "  - Centre: (1802, 2970)\n",
      "\n",
      "D√©tection #8:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.919\n",
      "  - Bounding box: x1=4247, y1=3177, x2=4310, y2=3245\n",
      "  - Dimensions: 63x68 pixels\n",
      "  - Centre: (4279, 3211)\n",
      "\n",
      "D√©tection #9:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.919\n",
      "  - Bounding box: x1=3752, y1=2561, x2=3811, y2=2619\n",
      "  - Dimensions: 59x58 pixels\n",
      "  - Centre: (3782, 2590)\n",
      "\n",
      "D√©tection #10:\n",
      "  - Classe: varroa\n",
      "  - Confiance: 0.917\n",
      "  - Bounding box: x1=2083, y1=4202, x2=2148, y2=4260\n",
      "  - Dimensions: 65x58 pixels\n",
      "  - Centre: (2116, 4231)\n"
     ]
    }
   ],
   "source": [
    "# D√©tection avec SAHI (Slicing Aided Hyper Inference)\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "from sahi.utils.cv import read_image\n",
    "import os\n",
    "\n",
    "# Charger le mod√®le via SAHI\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",  # Compatible avec YOLO11\n",
    "    model_path=\"model_mdpi_3291496/weights/best.pt\",\n",
    "    confidence_threshold=0.1,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "# Image √† analyser\n",
    "image_path = 'varroa-counter-v3-3/test/images/IMG_6098_jpg.rf.eb517a2863fbb704a84afce55b287455.jpg'\n",
    "\n",
    "# Effectuer la pr√©diction par d√©coupage\n",
    "result = get_sliced_prediction(\n",
    "    image_path,\n",
    "    detection_model,\n",
    "    slice_height=4096,\n",
    "    slice_width=4096,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    "    postprocess_type=\"NMS\",\n",
    "    postprocess_match_metric=\"IOU\",\n",
    "    postprocess_match_threshold=0.5\n",
    ")\n",
    "\n",
    "# Cr√©er le dossier de r√©sultats\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Exporter l'image avec SEULEMENT les bounding boxes (sans texte de classe)\n",
    "result.export_visuals(\n",
    "    export_dir=output_dir,\n",
    "    file_name=\"detection_result\",\n",
    "    hide_labels=True,      # Masque le texte de classe\n",
    "    hide_conf=True,        # Masque le score de confiance\n",
    "    rect_th=1              # √âpaisseur des rectangles\n",
    ")\n",
    "\n",
    "print(f\"Image export√©e dans: {output_dir}/detection_result.png\")\n",
    "\n",
    "# ============================================================\n",
    "# INFORMATIONS D√âTAILL√âES SUR LES R√âSULTATS\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"R√âSUM√â DE LA D√âTECTION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "object_predictions = result.object_prediction_list\n",
    "print(f\"\\nNombre total de varroas d√©tect√©s: {len(object_predictions)}\")\n",
    "\n",
    "# Statistiques sur les scores de confiance\n",
    "if object_predictions:\n",
    "    confidences = [pred.score.value for pred in object_predictions]\n",
    "    print(f\"\\nStatistiques de confiance:\")\n",
    "    print(f\"  - Confiance moyenne: {sum(confidences)/len(confidences):.3f}\")\n",
    "    print(f\"  - Confiance min: {min(confidences):.3f}\")\n",
    "    print(f\"  - Confiance max: {max(confidences):.3f}\")\n",
    "    \n",
    "    # Distribution par tranches de confiance\n",
    "    print(f\"\\nDistribution par niveau de confiance:\")\n",
    "    ranges = [(0.1, 0.3), (0.3, 0.5), (0.5, 0.7), (0.7, 0.9), (0.9, 1.0)]\n",
    "    for low, high in ranges:\n",
    "        count = sum(1 for c in confidences if low <= c < high)\n",
    "        print(f\"  - {low:.1f} - {high:.1f}: {count} d√©tections\")\n",
    "\n",
    "    # Statistiques sur les tailles des bounding boxes\n",
    "    areas = []\n",
    "    for pred in object_predictions:\n",
    "        bbox = pred.bbox\n",
    "        width = bbox.maxx - bbox.minx\n",
    "        height = bbox.maxy - bbox.miny\n",
    "        areas.append(width * height)\n",
    "    \n",
    "    print(f\"\\nStatistiques des bounding boxes (en pixels):\")\n",
    "    print(f\"  - Aire moyenne: {sum(areas)/len(areas):.1f} px¬≤\")\n",
    "    print(f\"  - Aire min: {min(areas):.1f} px¬≤\")\n",
    "    print(f\"  - Aire max: {max(areas):.1f} px¬≤\")\n",
    "\n",
    "# Afficher les d√©tails des 10 premi√®res d√©tections\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"D√âTAILS DES 10 PREMI√àRES D√âTECTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for i, pred in enumerate(object_predictions[:10]):\n",
    "    bbox = pred.bbox\n",
    "    print(f\"\\nD√©tection #{i+1}:\")\n",
    "    print(f\"  - Classe: {pred.category.name}\")\n",
    "    print(f\"  - Confiance: {pred.score.value:.3f}\")\n",
    "    print(f\"  - Bounding box: x1={bbox.minx:.0f}, y1={bbox.miny:.0f}, x2={bbox.maxx:.0f}, y2={bbox.maxy:.0f}\")\n",
    "    print(f\"  - Dimensions: {bbox.maxx - bbox.minx:.0f}x{bbox.maxy - bbox.miny:.0f} pixels\")\n",
    "    print(f\"  - Centre: ({(bbox.minx + bbox.maxx)/2:.0f}, {(bbox.miny + bbox.maxy)/2:.0f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporter les r√©sultats d√©taill√©s en CSV\n",
    "import csv\n",
    "\n",
    "csv_path = os.path.join(output_dir, \"detections.csv\")\n",
    "\n",
    "with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'classe', 'confiance', 'x1', 'y1', 'x2', 'y2', 'largeur', 'hauteur', 'aire', 'centre_x', 'centre_y'])\n",
    "    \n",
    "    for i, pred in enumerate(object_predictions):\n",
    "        bbox = pred.bbox\n",
    "        width = bbox.maxx - bbox.minx\n",
    "        height = bbox.maxy - bbox.miny\n",
    "        area = width * height\n",
    "        center_x = (bbox.minx + bbox.maxx) / 2\n",
    "        center_y = (bbox.miny + bbox.maxy) / 2\n",
    "        \n",
    "        writer.writerow([\n",
    "            i + 1,\n",
    "            pred.category.name,\n",
    "            f\"{pred.score.value:.4f}\",\n",
    "            f\"{bbox.minx:.1f}\",\n",
    "            f\"{bbox.miny:.1f}\",\n",
    "            f\"{bbox.maxx:.1f}\",\n",
    "            f\"{bbox.maxy:.1f}\",\n",
    "            f\"{width:.1f}\",\n",
    "            f\"{height:.1f}\",\n",
    "            f\"{area:.1f}\",\n",
    "            f\"{center_x:.1f}\",\n",
    "            f\"{center_y:.1f}\"\n",
    "        ])\n",
    "\n",
    "print(f\"R√©sultats export√©s en CSV: {csv_path}\")\n",
    "print(f\"\\nLe fichier contient {len(object_predictions)} d√©tections avec:\")\n",
    "print(\"  - ID unique\")\n",
    "print(\"  - Classe d√©tect√©e\")\n",
    "print(\"  - Score de confiance\")\n",
    "print(\"  - Coordonn√©es du bounding box (x1, y1, x2, y2)\")\n",
    "print(\"  - Dimensions (largeur, hauteur)\")\n",
    "print(\"  - Aire en pixels¬≤\")\n",
    "print(\"  - Coordonn√©es du centre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Varroa-board-1/test/images/IMG_0226_jpg.rf.c97161f83bb98300231bd6318d7dee3b.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m image_path = \u001b[33m'\u001b[39m\u001b[33mVarroa-board-1/test/images/IMG_0226_jpg.rf.c97161f83bb98300231bd6318d7dee3b.jpg\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Charger l'image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m width, height = img.size\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTaille originale de l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mimage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3493\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3492\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3493\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3494\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Varroa-board-1/test/images/IMG_0226_jpg.rf.c97161f83bb98300231bd6318d7dee3b.jpg'"
     ]
    }
   ],
   "source": [
    "# Test avec d√©coupage d'image en 4 parties\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Charger le mod√®le\n",
    "model = YOLO('model_mdpi_3291496/weights/best.pt')\n",
    "\n",
    "# Chemin de l'image √† tester\n",
    "image_path = 'Varroa-board-1/test/images/IMG_0226_jpg.rf.c97161f83bb98300231bd6318d7dee3b.jpg'\n",
    "\n",
    "# Charger l'image\n",
    "img = Image.open(image_path)\n",
    "width, height = img.size\n",
    "print(f\"Taille originale de l'image: {width}x{height}\")\n",
    "\n",
    "# Cr√©er un dossier pour les images d√©coup√©es\n",
    "output_dir = 'temp_tiles'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# D√©couper l'image en 4 parties (2x2)\n",
    "half_width = width // 2\n",
    "half_height = height // 2\n",
    "\n",
    "tiles = []\n",
    "positions = [\n",
    "    (0, 0, half_width, half_height, \"top_left\"),\n",
    "    (half_width, 0, width, half_height, \"top_right\"),\n",
    "    (0, half_height, half_width, height, \"bottom_left\"),\n",
    "    (half_width, half_height, width, height, \"bottom_right\")\n",
    "]\n",
    "\n",
    "# D√©couper et sauvegarder chaque partie\n",
    "for i, (x1, y1, x2, y2, name) in enumerate(positions):\n",
    "    tile = img.crop((x1, y1, x2, y2))\n",
    "    tile_path = os.path.join(output_dir, f'tile_{i+1}_{name}.jpg')\n",
    "    tile.save(tile_path)\n",
    "    tiles.append((tile_path, name, x1, y1))\n",
    "    print(f\"Partie {i+1} ({name}): {tile.size[0]}x{tile.size[1]} sauvegard√©e\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"D√âTECTION SUR CHAQUE PARTIE\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Tester le mod√®le sur chaque partie\n",
    "total_detections = 0\n",
    "all_results = []\n",
    "\n",
    "for tile_path, name, offset_x, offset_y in tiles:\n",
    "    print(f\"\\n--- D√©tection sur {name} ---\")\n",
    "    results = model.predict(\n",
    "        source=tile_path,\n",
    "   imgsz=(6016), max_det=2000, conf=0.1, iou = 0.5,\n",
    "    save=True, show_labels=False, line_width=2, save_txt=True, save_conf=True\n",
    "    )\n",
    "    \n",
    "    detections = len(results[0].boxes)\n",
    "    total_detections += detections\n",
    "    all_results.append((name, detections, results[0]))\n",
    "    \n",
    "    print(f\"Varroas d√©tect√©s: {detections}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"R√âSUM√â DES D√âTECTIONS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nNombre total de varroas d√©tect√©s: {total_detections}\")\n",
    "print(\"\\nD√©tail par partie:\")\n",
    "for name, count, _ in all_results:\n",
    "    print(f\"  - {name:15s}: {count:3d} varroas\")\n",
    "\n",
    "print(f\"\\nImages d√©coup√©es sauvegard√©es dans: {output_dir}/\")\n",
    "print(f\"R√©sultats de d√©tection sauvegard√©s dans: runs/detect/predict*/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_filtered_dataset(source_dir, dest_dir, prefix=\"IMG_6\"):\n",
    "    \"\"\"\n",
    "    Cr√©e une copie d'un dataset YOLO en ne gardant que les images\n",
    "    dont le nom commence par le pr√©fixe sp√©cifi√©.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Chemin du dataset source (ex: \"varroa-counter-v3-3\")\n",
    "        dest_dir: Chemin du dataset destination\n",
    "        prefix: Pr√©fixe des images √† conserver (ex: \"IMG_6\")\n",
    "    \"\"\"\n",
    "    source_dir = Path(source_dir)\n",
    "    dest_dir = Path(dest_dir)\n",
    "\n",
    "    # Copier data.yaml et fichiers README\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for f in source_dir.glob(\"*.yaml\"):\n",
    "        shutil.copy2(f, dest_dir / f.name)\n",
    "    for f in source_dir.glob(\"*.txt\"):\n",
    "        shutil.copy2(f, dest_dir / f.name)\n",
    "\n",
    "    total_copied = 0\n",
    "\n",
    "    # Parcourir les splits (train, valid, test)\n",
    "    for split_dir in source_dir.iterdir():\n",
    "        if not split_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        images_dir = split_dir / \"images\"\n",
    "        labels_dir = split_dir / \"labels\"\n",
    "\n",
    "        if not images_dir.exists():\n",
    "            continue\n",
    "\n",
    "        # Cr√©er les dossiers de destination\n",
    "        dest_images = dest_dir / split_dir.name / \"images\"\n",
    "        dest_labels = dest_dir / split_dir.name / \"labels\"\n",
    "        dest_images.mkdir(parents=True, exist_ok=True)\n",
    "        dest_labels.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Copier les images correspondant au pr√©fixe et leurs labels\n",
    "        for img_file in images_dir.iterdir():\n",
    "            if img_file.name.startswith(prefix):\n",
    "                shutil.copy2(img_file, dest_images / img_file.name)\n",
    "\n",
    "                # Copier le label correspondant (.txt)\n",
    "                label_file = labels_dir / (img_file.stem + \".txt\")\n",
    "                if label_file.exists():\n",
    "                    shutil.copy2(label_file, dest_labels / label_file.name)\n",
    "\n",
    "                total_copied += 1\n",
    "\n",
    "    print(f\"Dataset filtr√© cr√©√© dans: {dest_dir}\")\n",
    "    print(f\"Images copi√©es: {total_copied}\")\n",
    "\n",
    "    # Lister le contenu\n",
    "    for split_dir in sorted(dest_dir.iterdir()):\n",
    "        if split_dir.is_dir():\n",
    "            imgs = list((split_dir / \"images\").glob(\"*\"))\n",
    "            print(f\"  {split_dir.name}: {len(imgs)} images\")\n",
    "\n",
    "\n",
    "# Cr√©er le dataset filtr√© avec uniquement les images IMG_6xxx\n",
    "create_filtered_dataset(\n",
    "    source_dir=\"varroa-counter-v3-3\",\n",
    "    dest_dir=\"varroa-counter-v3-3-IMG6\",\n",
    "    prefix=\"IMG_6\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
